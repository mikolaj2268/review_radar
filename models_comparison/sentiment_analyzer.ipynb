{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "TensorFlow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plik Parquet zosta≈Ç pomy≈õlnie wczytany.\n",
      "Dostƒôpne kolumny: ['review_id', 'at', 'content', 'score', 'app_name']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "parquet_path = 'models_comparison/reviews.parquet'\n",
    "\n",
    "if not os.path.exists(parquet_path):\n",
    "    print(f\"Parquet file not found at path: {parquet_path}\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "    print(\"Parquet file successfully loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Parquet file: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(\"Available columns:\", df.columns.tolist())\n",
    "if 'content' not in df.columns:\n",
    "    print(\"The 'content' column was not found in the Parquet file.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content\n",
      "<class 'str'>    698688\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['content'].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## obliczenie sentymentu dla 4 modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is enabled\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS is enabled\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zwracanie wszystkich wartosci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS (Metal Performance Shaders) device is available. Using GPU acceleration.\n",
      "Parquet file successfully loaded.\n",
      "Available columns: ['review_id', 'at', 'content', 'score', 'app_name']\n",
      "Loading DistilBERT model...\n",
      "Loading Cardiff NLP RoBERTa model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment using TextBlob...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 698688/698688 [00:44<00:00, 15646.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment using VADER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 698688/698688 [00:16<00:00, 42523.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment using DistilBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing DistilBERT in Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21834/21834 [30:15<00:00, 12.03it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment using Cardiff NLP RoBERTa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing RoBERTa in Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21834/21834 [1:05:41<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              review_id          at  \\\n",
      "0  4423e3f0-6002-469c-bf91-239a1ba1d998  2024-11-23   \n",
      "1  16d24c6a-d3ea-4558-9a6b-2694beb581ec  2024-11-23   \n",
      "2  14098fe6-6649-4fb4-aeb1-f1b36fdcca6f  2024-11-23   \n",
      "3  6b215132-0eaf-40f7-a7f4-758c8fbf35b1  2024-11-23   \n",
      "4  b57b2878-92ba-4468-a3dc-722f2c61b51b  2024-11-23   \n",
      "\n",
      "                                             content  score app_name  \\\n",
      "0                                      No comment üò≠üòî      5  Netflix   \n",
      "1  lately the sounds go thru but no picture...its...      2  Netflix   \n",
      "2                                 This is very goodüëç      5  Netflix   \n",
      "3  Why auto payment with bank is activated after ...      1  Netflix   \n",
      "4  Keeps updating every 2 days and suddenly canno...      1  Netflix   \n",
      "\n",
      "   textblob_pattern_polarity  textblob_pattern_subjectivity  vader_neg  \\\n",
      "0                       0.00                           0.00      0.500   \n",
      "1                      -0.55                           0.75      0.205   \n",
      "2                       0.20                           0.30      0.000   \n",
      "3                       0.00                           0.00      0.000   \n",
      "4                       0.00                           0.50      0.000   \n",
      "\n",
      "   vader_neu  vader_pos  vader_compound  distilbert_negative_prob  \\\n",
      "0      0.377      0.123         -0.6124                  0.987631   \n",
      "1      0.584      0.211          0.0225                  0.999301   \n",
      "2      0.610      0.390          0.4927                  0.034944   \n",
      "3      1.000      0.000          0.0000                  0.996918   \n",
      "4      1.000      0.000          0.0000                  0.999739   \n",
      "\n",
      "   distilbert_positive_prob  distilbert_sentiment_score  \\\n",
      "0                  0.012369                   -0.975263   \n",
      "1                  0.000699                   -0.998603   \n",
      "2                  0.965056                    0.930112   \n",
      "3                  0.003082                   -0.993837   \n",
      "4                  0.000261                   -0.999478   \n",
      "\n",
      "  distilbert_sentiment_label  roberta_negative_prob  roberta_neutral_prob  \\\n",
      "0                   NEGATIVE               0.817729              0.172929   \n",
      "1                   NEGATIVE               0.913306              0.082218   \n",
      "2                   POSITIVE               0.004413              0.011624   \n",
      "3                   NEGATIVE               0.207172              0.769924   \n",
      "4                   NEGATIVE               0.779235              0.208691   \n",
      "\n",
      "   roberta_positive_prob roberta_sentiment_label  \n",
      "0               0.009343                NEGATIVE  \n",
      "1               0.004477                NEGATIVE  \n",
      "2               0.983962                POSITIVE  \n",
      "3               0.022904                 NEUTRAL  \n",
      "4               0.012074                NEGATIVE  \n",
      "Results have been saved to: models_comparison/reviews_with_sentiments.parquet\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS (Metal Performance Shaders) device is available. Using GPU acceleration.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU device found. Using CPU.\")\n",
    "\n",
    "parquet_path = 'models_comparison/reviews.parquet'\n",
    "\n",
    "if not os.path.exists(parquet_path):\n",
    "    print(f\"Parquet file not found at path: {parquet_path}\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "    print(\"Parquet file successfully loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Parquet file: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(\"Available columns:\", df.columns.tolist())\n",
    "if 'content' not in df.columns:\n",
    "    print(\"The 'content' column was not found in the Parquet file.\")\n",
    "    exit()\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "print(\"Loading DistilBERT model...\")\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "distilbert_model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "distilbert_model.to(device)\n",
    "distilbert_model.eval()\n",
    "\n",
    "print(\"Loading Cardiff NLP RoBERTa model...\")\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "roberta_model.to(device)\n",
    "roberta_model.eval()\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "def analyze_textblob(text):\n",
    "    try:\n",
    "        blob = TextBlob(str(text))\n",
    "        sentiment = blob.sentiment  # returns Sentiment(polarity, subjectivity)\n",
    "\n",
    "        return {\n",
    "            'textblob_pattern_polarity': sentiment.polarity,\n",
    "            'textblob_pattern_subjectivity': sentiment.subjectivity\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"TextBlob error for text: {text}\\nError: {e}\")\n",
    "        return {\n",
    "            'textblob_pattern_polarity': None,\n",
    "            'textblob_pattern_subjectivity': None\n",
    "        }\n",
    "\n",
    "# Function to analyze sentiment using VADER\n",
    "def analyze_vader(text):\n",
    "    try:\n",
    "        scores = analyzer.polarity_scores(str(text))\n",
    "        return {\n",
    "            'vader_neg': scores['neg'],\n",
    "            'vader_neu': scores['neu'],\n",
    "            'vader_pos': scores['pos'],\n",
    "            'vader_compound': scores['compound']\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"VADER error for text: {text}\\nError: {e}\")\n",
    "        return {\n",
    "            'vader_neg': None,\n",
    "            'vader_neu': None,\n",
    "            'vader_pos': None,\n",
    "            'vader_compound': None\n",
    "        }\n",
    "\n",
    "# Function to analyze sentiment using DistilBERT in batches\n",
    "def analyze_distilbert_batch(texts, batch_size=32):\n",
    "    sentiments = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Analyzing DistilBERT in Batches\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        try:\n",
    "            inputs = distilbert_tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = distilbert_model(**inputs)\n",
    "\n",
    "            probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            probs = probabilities.tolist()\n",
    "\n",
    "            for prob in probs:\n",
    "                negative_prob, positive_prob = prob\n",
    "\n",
    "                sentiments.append({\n",
    "                    'distilbert_negative_prob': negative_prob,\n",
    "                    'distilbert_positive_prob': positive_prob\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"DistilBERT error for batch {i}-{i+batch_size}: {e}\")\n",
    "            for _ in batch:\n",
    "                sentiments.append({\n",
    "                    'distilbert_negative_prob': None,\n",
    "                    'distilbert_positive_prob': None\n",
    "                })\n",
    "    return sentiments\n",
    "\n",
    "# Function to analyze sentiment using Cardiff NLP RoBERTa in batches\n",
    "def analyze_roberta_batch(texts, batch_size=32):\n",
    "    sentiments = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Analyzing RoBERTa in Batches\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        try:\n",
    "            inputs = roberta_tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = roberta_model(**inputs)\n",
    "\n",
    "            probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            probs = probabilities.tolist()\n",
    "\n",
    "            for prob in probs:\n",
    "                negative_prob, neutral_prob, positive_prob = prob\n",
    "                sentiment_label = max(\n",
    "                    [\"NEGATIVE\", \"NEUTRAL\", \"POSITIVE\"],\n",
    "                    key=lambda x: {\"NEGATIVE\": negative_prob, \"NEUTRAL\": neutral_prob, \"POSITIVE\": positive_prob}[x],\n",
    "                )\n",
    "                sentiments.append({\n",
    "                    'roberta_negative_prob': negative_prob,\n",
    "                    'roberta_neutral_prob': neutral_prob,\n",
    "                    'roberta_positive_prob': positive_prob,\n",
    "                    'roberta_sentiment_label': sentiment_label\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"RoBERTa error for batch {i}-{i+batch_size}: {e}\")\n",
    "            for _ in batch:\n",
    "                sentiments.append({\n",
    "                    'roberta_negative_prob': None,\n",
    "                    'roberta_neutral_prob': None,\n",
    "                    'roberta_positive_prob': None,\n",
    "                    'roberta_sentiment_label': None\n",
    "                })\n",
    "    return sentiments\n",
    "\n",
    "\n",
    "print(\"Analyzing sentiment using TextBlob...\")\n",
    "textblob_results = df['content'].progress_apply(analyze_textblob).tolist()\n",
    "textblob_df = pd.DataFrame(textblob_results)\n",
    "df = pd.concat([df.reset_index(drop=True), textblob_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(\"Analyzing sentiment using VADER...\")\n",
    "vader_results = df['content'].progress_apply(analyze_vader).tolist()\n",
    "vader_df = pd.DataFrame(vader_results)\n",
    "df = pd.concat([df.reset_index(drop=True), vader_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(\"Analyzing sentiment using DistilBERT...\")\n",
    "distilbert_results = analyze_distilbert_batch(df['content'].tolist())\n",
    "distilbert_df = pd.DataFrame(distilbert_results)\n",
    "df = pd.concat([df.reset_index(drop=True), distilbert_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(\"Analyzing sentiment using Cardiff NLP RoBERTa...\")\n",
    "roberta_results = analyze_roberta_batch(df['content'].tolist())\n",
    "roberta_df = pd.DataFrame(roberta_results)\n",
    "df = pd.concat([df.reset_index(drop=True), roberta_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "output_path = 'models_comparison/reviews_with_sentiments.parquet'\n",
    "try:\n",
    "    df.to_parquet(output_path, index=False)\n",
    "    print(f\"Results have been saved to: {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving Parquet file:{e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
